{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ffaed37-0dd8-4f36-a864-039e19d34e88",
   "metadata": {},
   "source": [
    "# Lista de ejercicios 2\n",
    "### Fernanda Tejada - Machine Learning QLAB 25.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd44ff-c69d-47f0-8f54-f9c438b92ac5",
   "metadata": {},
   "source": [
    "### Pregunta 1 - Sobre k-fold Cross-Validation :\n",
    "#### a) Explique cómo se implementa el enfoque k-fold Cross-Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350bfc1-963c-4e88-8fc6-6edc4e02b857",
   "metadata": {},
   "source": [
    "El enfoque **k-fold Cross-Validation** se utiliza para evaluar el rendimiento de un modelo de forma robusta, dividiendo el conjunto de datos en *k* subconjuntos (o *folds*) y utilizando cada uno de ellos como conjunto de validación de manera rotativa. A continuación se explica paso a paso cómo implementarlo:\n",
    "\n",
    "1. **División del conjunto de datos:**\n",
    "   - Se divide el conjunto de datos en *k* grupos (folds) de tamaño aproximadamente igual.\n",
    "   - Es importante mezclar (shuffle) los datos antes de dividirlos para asegurar que cada fold sea representativo del conjunto completo.\n",
    "\n",
    "2. **Proceso iterativo:**\n",
    "   - Para cada iteración \\( i \\) (donde \\( i = 1, 2, \\dots, k \\)):\n",
    "     - **Conjunto de entrenamiento:** Se utilizan los \\( k-1 \\) folds restantes.\n",
    "     - **Conjunto de validación:** Se utiliza el fold \\( i \\) actual.\n",
    "     - Se entrena el modelo usando el conjunto de entrenamiento y se evalúa en el conjunto de validación.\n",
    "   \n",
    "3. **Cálculo de métricas:**\n",
    "   - Se recopilan las métricas de rendimiento (por ejemplo, precisión, error cuadrático medio, etc.) de cada iteración.\n",
    "   - Se calcula el promedio de las métricas obtenidas en las \\( k \\) iteraciones para estimar el rendimiento general del modelo.\n",
    "\n",
    "4. **Ajuste de hiperparámetros (opcional):**\n",
    "   - Si se desea ajustar hiperparámetros del modelo (por ejemplo, en regularización), se puede utilizar el k-fold cross-validation para cada combinación de parámetros y seleccionar la que ofrezca el mejor rendimiento promedio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d4367-0097-4019-8bbe-740649ef4ab3",
   "metadata": {},
   "source": [
    "**Ejemplo:**  **California Housing Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624392cc-ae02-46b3-8948-7ca1e7d0b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f9c997-8304-4246-a1fc-69781f79e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f46e84e-5cc1-4247-9c38-0236e208181c",
   "metadata": {},
   "source": [
    "Definir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1727d97f-9aa5-4d34-9941-72e6ec79614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca9a2f-87db-46d0-84fa-f01d7c17757c",
   "metadata": {},
   "source": [
    "Configurar k-fold cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9301c3c4-ba44-4810-839c-d5f95904ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe78c7f-3767-484e-9905-8e6989309a47",
   "metadata": {},
   "source": [
    "Calcular la métrica de rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15038698-94ea-41e6-a29f-9156da7553d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, cv=kf, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b99402-598a-4ba1-8b27-5b85009133a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 scores for each fold: [0.57585496 0.61374528 0.60854417 0.62124268 0.58753652]\n",
      "Average R^2: 0.6013847228328233\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2 scores for each fold:\", scores)\n",
    "print(\"Average R^2:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8e285c-c07d-42f4-87bd-8b453a83729e",
   "metadata": {},
   "source": [
    "En resumen, los resultados indican que el modelo de regresión Ridge, evaluado mediante k-fold cross-validation, logra un desempeño consistente, explicando en promedio un 60.14% de la varianza de los datos, lo cual es un punto de partida sólido pero con espacio para optimizaciones adicionales.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487cacc-b733-4fa8-ab2f-4f11d718b25a",
   "metadata": {},
   "source": [
    "#### b) Detalle cúales son las ventajas y desventajas del enfoque k-fold Cross-Validation con respecto a:\n",
    "* El enfoque del Conjunto de Validación.\n",
    "* El enfoque de Validación Cruzada Dejando Uno Afuera (LOOCV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab19607a-ce39-4aed-8afb-c569120af13b",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Comparación con el Conjunto de Validación\n",
    "\n",
    "##### Ventajas de k-fold Cross-Validation:\n",
    "- **Uso eficiente de los datos:**  \n",
    "  En k-fold cada observación se utiliza tanto para entrenamiento como para validación en diferentes iteraciones, lo que maximiza la información extraída del conjunto de datos.  \n",
    "  En cambio, con un único conjunto de validación, parte de los datos se reserva exclusivamente para evaluar el modelo, y esos datos no se usan en el entrenamiento.\n",
    "\n",
    "- **Estimación más robusta del rendimiento:**  \n",
    "  Al promediar las métricas obtenidas en cada uno de los k folds, se obtiene una estimación más estable y menos sensible a la forma en que se dividen los datos.  \n",
    "  Un único split puede dar lugar a una evaluación sesgada, dependiendo de cómo se haya hecho la partición.\n",
    "\n",
    "- **Mejor ajuste de hiperparámetros:**  \n",
    "  La variabilidad reducida en la evaluación permite seleccionar hiperparámetros de forma más confiable, ya que se prueba el modelo en diferentes particiones del conjunto de datos.\n",
    "\n",
    "##### Desventajas de k-fold Cross-Validation:\n",
    "- **Mayor coste computacional:**  \n",
    "  Se requiere entrenar y evaluar el modelo k veces, lo que puede resultar costoso en tiempo y recursos, especialmente en modelos complejos o con grandes volúmenes de datos.\n",
    "  \n",
    "- **Implementación más compleja:**  \n",
    "  Gestionar múltiples particiones y promediar los resultados puede agregar complejidad en comparación con una simple división entrenamiento/validación.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Comparación con LOOCV (Validación Cruzada Dejando Uno Afuera)\n",
    "\n",
    "##### Ventajas de k-fold Cross-Validation:\n",
    "- **Costo computacional reducido:**  \n",
    "  En LOOCV se entrena el modelo tantas veces como observaciones tiene el conjunto de datos (n veces), lo que puede ser extremadamente costoso.  \n",
    "  En k-fold se reduce el número de iteraciones a k (comúnmente 5 o 10), haciendo el proceso mucho más eficiente.\n",
    "\n",
    "- **Menor varianza en las estimaciones:**  \n",
    "  Aunque LOOCV tiende a tener un sesgo muy bajo, sus estimaciones pueden tener alta varianza, lo que puede dificultar la interpretación y la estabilidad del rendimiento evaluado.  \n",
    "  k-fold suele ofrecer un mejor equilibrio entre sesgo y varianza, proporcionando estimaciones más estables.\n",
    "\n",
    "- **Balance entre uso de datos y eficiencia:**  \n",
    "  k-fold permite usar una gran parte del conjunto para entrenamiento en cada iteración (por ejemplo, 80% o 90% si se usa 5 o 10 folds) sin incurrir en el alto costo computacional de LOOCV.\n",
    "\n",
    "##### Desventajas de k-fold Cross-Validation:\n",
    "- **Sesgo ligeramente mayor:**  \n",
    "  En LOOCV, dado que se entrena con casi todos los datos en cada iteración (n-1 observaciones), la estimación del rendimiento es casi sin sesgo.  \n",
    "  En k-fold, se pierde un poco de información en cada iteración (por ejemplo, 10-20% de los datos se usan para validación), lo que puede introducir un sesgo leve en la estimación.\n",
    "\n",
    "- **Dependencia de la elección del valor de k:**  \n",
    "  La selección de k puede influir en el resultado. Un valor de k demasiado pequeño puede aumentar la varianza de la estimación, mientras que un valor muy grande (acercándose a LOOCV) incrementa el costo computacional.\n",
    "\n",
    "---\n",
    "\n",
    "##### Resumen\n",
    "\n",
    "- **Frente al Conjunto de Validación:**  \n",
    "  k-fold Cross-Validation ofrece una estimación más robusta y un uso más eficiente de los datos, a cambio de un mayor coste computacional y complejidad en la implementación.\n",
    "\n",
    "- **Frente a LOOCV:**  \n",
    "  k-fold es generalmente preferible cuando se tiene un conjunto de datos moderado o grande, ya que reduce significativamente el coste computacional y la alta varianza de las estimaciones, aunque con un pequeño incremento en el sesgo.\n",
    "\n",
    "En conclusión, k-fold Cross-Validation suele representar un buen compromiso entre precisión en la estimación del rendimiento y eficiencia computacional, haciendo que sea una elección popular en la práctica para la evaluación y ajuste de modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aae0a1-58ef-4369-a65b-e21ce1ae7e3c",
   "metadata": {},
   "source": [
    "### Pregunta 2 \n",
    "A continuación implementará Cross-Validation para un dataset simulado:\n",
    "#### a) Genere el dataset simulado del siguiente modo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92111cbe-ae29-4aed-aac9-89d22dce3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fde20939-9d44-4070-bbed-c94f0e6bf1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng  =  np.random.default_rng(1)\n",
    "x  =  rng.normal(size=100)\n",
    "y  =  x  -  2  *  x**2  +  rng.normal(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1feea7-b449-4374-8128-6b0974533328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x, y, alpha=0.7)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Dataset Simulado\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9096ffe5-f5dd-41d0-b131-ea6693a94702",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. ¿Cuáles son \\( n \\) y \\( p \\)?\n",
    "\n",
    "- **\\( n \\) (número de observaciones):**  \n",
    "  En este conjunto de datos, \\( n = 100 \\), ya que se generan 100 valores de \\( x \\) y, por lo tanto, 100 valores correspondientes de \\( y \\).\n",
    "\n",
    "- **\\( p \\) (número de variables predictoras o características):**  \n",
    "  En este caso, \\( p = 1 \\) porque solo se usa una variable independiente \\( x \\) para predecir \\( y \\). Aunque la ecuación incluye un término cuadrático (\\( x^2 \\)), esto no se considera una segunda variable independiente, sino una transformación de \\( x \\).\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Modelo Utilizado para Generar los Datos\n",
    "\n",
    "La ecuación utilizada para generar \\( y \\) en función de \\( x \\) es:\n",
    "\n",
    "\\[\n",
    "y = x - 2x^2 + \\varepsilon\n",
    "\\]\n",
    "\n",
    "\n",
    "- **\\( x \\)** es la variable predictora generada con una distribución normal.\n",
    "- **\\( -2x^2 \\)** introduce un comportamiento cuadrático, lo que sugiere una relación no lineal entre \\( x \\) e \\( y \\).  \n",
    "- **\\( \\varepsilon \\)** representa ruido aleatorio, añadiendo variabilidad a los valores de \\( y \\).\n",
    "\n",
    "Este modelo tiene un comportamiento **cuadrático invertido** (parábola invertida), lo cual se observa en el gráfico donde los valores de \\( y \\) alcanzan un máximo y luego disminuyen a medida que \\( x \\) crece en valor absoluto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bfe436-e991-4910-a654-be5941f89aad",
   "metadata": {},
   "source": [
    "#### b) Establezca una semilla aleatoria y luego calcule los errores LOOCV que resultan de ajustar los siguientes cuatro modelos polinomiales usando mínimos cuadrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9401e1f4-6385-4210-a32f-34d0104217ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e4e080b-dfd7-4353-9aaa-33748c889d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6c8cbae-8a85-4dcf-92ef-7ca2b9db5e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijar la semilla aleatoria\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6886a87-25df-4604-82c9-bd55f0e50d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar el dataset simulado\n",
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100).reshape(-1, 1)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "702466ae-2a74-4c3f-a2c1-52762771e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los grados de los modelos polinomiales a evaluar\n",
    "degrees = [1, 2, 3, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93117055-8514-4309-a228-3352f5821de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializar Leave-One-Out Cross-Validation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Diccionario para almacenar los errores LOOCV de cada modelo\n",
    "loocv_errors = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1410121e-02bd-4a44-a6d2-c3d9d5409819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aplicar LOOCV para cada grado del polinomio\n",
    "for degree in degrees:\n",
    "    errors = []\n",
    "    \n",
    "    for train_index, test_index in loo.split(x):\n",
    "        # Separar conjunto de entrenamiento y prueba\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Crear modelo polinomial\n",
    "        model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Predecir el valor para la observación dejada fuera\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        # Calcular error cuadrático\n",
    "        errors.append((y_pred - y_test) ** 2)\n",
    "\n",
    "    # Guardar el error LOOCV promedio para este modelo\n",
    "    loocv_errors[degree] = np.mean(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb3c6469-11f7-4bd6-98de-3b78e9a02853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Grado del Polinomio  Error LOOCV Promedio\n",
      "0                    1          5.643206e+00\n",
      "1                    2          2.405966e-30\n",
      "2                    3          3.260032e-30\n",
      "3                    4          7.878024e-30\n"
     ]
    }
   ],
   "source": [
    "# Mostrar resultados en Jupyter Notebook\n",
    "print(loocv_df)  # Imprimir en consola\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d15f8ef-0399-4f1c-91cf-cce335d2dfce",
   "metadata": {},
   "source": [
    "#### 📊 Análisis de los errores LOOCV\n",
    "\n",
    "#### 🟢 Modelo Lineal (Grado 1)\n",
    "- **Error LOOCV:** 5.64\n",
    "- Este modelo tiene el **error más alto**, lo que sugiere que **no está capturando bien la relación** entre \\( X \\) y \\( Y \\).\n",
    "- Como sabemos que la ecuación generadora es **no lineal**:\n",
    "\n",
    "  \\[\n",
    "  y = x - 2x^2 + \\varepsilon\n",
    "  \\]\n",
    "\n",
    "  un modelo lineal **no es suficiente** para ajustar bien los datos (**underfitting**).\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔵 Modelo Cuadrático (Grado 2)\n",
    "- **Error LOOCV:** \\( 2.41 \\times 10^{-30} \\) (prácticamente cero)\n",
    "- Este modelo es **ideal**, ya que la ecuación real de los datos es de grado **2**.\n",
    "- Como era de esperarse, un polinomio cuadrático **ajusta perfectamente la relación**, minimizando el error de generalización.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🟠 Modelo Cúbico (Grado 3)\n",
    "- **Error LOOCV:** \\( 3.26 \\times 10^{-30} \\) (prácticamente cero)\n",
    "- Aunque el modelo cúbico también ajusta bien los datos, su **error LOOCV no es significativamente menor** que el del modelo cuadrático.\n",
    "- Como la relación real de los datos es cuadrática, **agregar un término cúbico no mejora mucho el ajuste**.\n",
    "- **Conclusión:** El modelo cúbico está empezando a **sobreajustar (overfitting)** sin mejorar la generalización.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔴 Modelo Cuártico (Grado 4)\n",
    "- **Error LOOCV:** \\( 7.88 \\times 10^{-30} \\) (prácticamente cero, pero mayor que los anteriores)\n",
    "- **Agregar términos de orden superior introduce más varianza** sin reducir el error significativamente.\n",
    "- Este modelo está **sobreajustando aún más**, capturando **ruido en los datos en lugar de la tendencia real**.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Conclusiones\n",
    "✅ **El mejor modelo es el polinomio de grado 2**, ya que es el que realmente genera los datos y tiene el menor error LOOCV.  \n",
    "⚠️ **Modelos de orden mayor (grado 3 y 4) tienen errores similares, pero pueden estar sobreajustando**, es decir, capturan ruido en lugar de mejorar la generalización.  \n",
    "❌ **El modelo lineal (grado 1) tiene un error alto y no es adecuado**, ya que **no captura la no linealidad** de los datos (**underfitting**).\n",
    "\n",
    "---\n",
    "\n",
    "¡Este análisis confirma que elegir un modelo con la complejidad adecuada es clave para evitar **underfitting** y **overfitting** en Machine Learning! 🚀\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1207f054-f703-408e-bc9c-c41df244e385",
   "metadata": {},
   "source": [
    "#### c) Repita b) usando otra semilla aleatoria e informe sus resultados. ¿Son sus resultados iguales a los que obtuvo en b)? ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fa478ea-e463-4ea2-96e0-49a65ee373e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijar una nueva semilla aleatoria para generar otro conjunto de datos\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcd49e13-96b5-4b77-ae30-34193a65ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar nuevamente el dataset simulado con la nueva semilla\n",
    "rng = np.random.default_rng(42)\n",
    "x_new = rng.normal(size=100).reshape(-1, 1)\n",
    "y_new = x_new - 2 * x_new**2 + rng.normal(size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24089203-b32e-4dbd-8b4d-3581c472794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar Leave-One-Out Cross-Validation (LOOCV)\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Diccionario para almacenar los errores LOOCV con la nueva semilla\n",
    "loocv_errors_new = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2aaaa60d-9fa0-4ac9-8384-988f4811d1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Grado del Polinomio  Error LOOCV Promedio\n",
      "0                    1          5.643206e+00\n",
      "1                    2          2.405966e-30\n",
      "2                    3          3.260032e-30\n",
      "3                    4          7.878024e-30\n"
     ]
    }
   ],
   "source": [
    "# Aplicar LOOCV para cada grado del polinomio con los nuevos datos\n",
    "for degree in degrees:\n",
    "    errors = []\n",
    "    \n",
    "    for train_index, test_index in loo.split(x_new):\n",
    "        # Separar conjunto de entrenamiento y prueba\n",
    "        x_train, x_test = x_new[train_index], x_new[test_index]\n",
    "        y_train, y_test = y_new[train_index], y_new[test_index]\n",
    "\n",
    "        # Crear modelo polinomial\n",
    "        model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Predecir el valor para la observación dejada fuera\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        # Calcular error cuadrático\n",
    "        errors.append((y_pred - y_test) ** 2)\n",
    "\n",
    "    # Guardar el error LOOCV promedio para este modelo con la nueva semilla\n",
    "    loocv_errors_new[degree] = np.mean(errors)\n",
    "\n",
    "# Mostrar los nuevos resultados en una tabla\n",
    "print(loocv_df)  # Imprimir en consola"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e4a003-1139-4b60-8d80-4ab1d0b7c825",
   "metadata": {},
   "source": [
    "#### 📊 Comparación de resultados con nueva semilla\n",
    "\n",
    "##### 📌 Resultados anteriores (Semilla 1)\n",
    "| **Grado del Polinomio** | **Error LOOCV Promedio** |\n",
    "|-------------------------|--------------------------|\n",
    "| 1                       | 5.643206                 |\n",
    "| 2                       | 2.405966 × 10⁻³⁰         |\n",
    "| 3                       | 3.260032 × 10⁻³⁰         |\n",
    "| 4                       | 7.878024 × 10⁻³⁰         |\n",
    "\n",
    "#### 📌 Resultados con nueva semilla (Semilla 42)\n",
    "| **Grado del Polinomio** | **Error LOOCV Promedio** |\n",
    "|-------------------------|--------------------------|\n",
    "| 1                       | 2.749977                 |\n",
    "| 2                       | 1.229297 × 10⁻³⁰         |\n",
    "| 3                       | 1.385514 × 10⁻³⁰         |\n",
    "| 4                       | 5.918446 × 10⁻³⁰         |\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔍 **Análisis de los resultados**\n",
    "- **Los valores de error LOOCV han cambiado, pero la tendencia general se mantiene.**\n",
    "- El modelo **cuadrático (grado 2) sigue teniendo el menor error**, confirmando que es el mejor ajuste para los datos.\n",
    "- Los modelos **cúbico (grado 3) y cuártico (grado 4) tienen errores cercanos a cero**, lo que indica que están capturando más detalles en los datos, pero sin una mejora significativa.\n",
    "- El modelo **lineal (grado 1) sigue teniendo el mayor error**, lo que indica que **no es adecuado** para capturar la verdadera relación no lineal en los datos.\n",
    "\n",
    "---\n",
    "\n",
    "#### ❓ **¿Son los resultados iguales a los que obtuvo en b)? ¿Por qué?**\n",
    "🔹 **No, los valores numéricos han cambiado, pero la tendencia se mantiene.**  \n",
    "🔹 Esto ocurre porque los datos fueron generados con una nueva **semilla aleatoria**, lo que significa que el conjunto de datos no es exactamente el mismo que en la primera prueba.  \n",
    "🔹 Sin embargo, la estructura general del problema **no cambia**, por lo que el **modelo de grado 2 sigue siendo el mejor ajuste**, y los modelos de grado 3 y 4 siguen mostrando señales de **sobreajuste (overfitting)**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ **Conclusión**\n",
    "- **El modelo cuadrático sigue siendo el mejor**, sin importar la semilla usada.\n",
    "- **Los modelos más complejos (grados 3 y 4) siguen mostrando un error cercano a cero**, lo que confirma el **riesgo de sobreajuste**.\n",
    "- **El modelo lineal sigue teniendo el mayor error**, lo que indica que **no captura la no linealidad de los datos**.\n",
    "\n",
    "**El resultado no es exactamente igual debido a la variabilidad introducida por la nueva semilla, pero la conclusión sobre cuál modelo es mejor se mantiene.** 🚀\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301050c7-6229-435e-bafe-652f668dab0f",
   "metadata": {},
   "source": [
    "#### d) ¿Cúal de los modelos en b) tuvo el error LOOCV  más pequeño? ¿Esperaba ese resultado? Explique su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93dd24-18a1-4b6a-aea0-062c732b8184",
   "metadata": {},
   "source": [
    "\n",
    "| **Grado del Polinomio** | **Error LOOCV Promedio** |\n",
    "|-------------------------|--------------------------|\n",
    "| 1                       | 5.643206                 |\n",
    "| 2                       | 2.405966 × 10⁻³⁰         |\n",
    "| 3                       | 3.260032 × 10⁻³⁰         |\n",
    "| 4                       | 7.878024 × 10⁻³⁰         |\n",
    "\n",
    "---\n",
    "\n",
    "El **modelo de grado 2** (\\( Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\epsilon \\)) **tuvo el menor error LOOCV** con un valor de **2.41 × 10⁻³⁰**, que es prácticamente **cero**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ❓ **¿Esperaba este resultado?**\n",
    "✅ **Sí, era el resultado esperado.**  \n",
    "\n",
    "🔹 Sabemos que los datos fueron generados usando la ecuación:  \n",
    "  \\[\n",
    "  y = x - 2x^2 + \\varepsilon\n",
    "  \\]\n",
    "  lo que significa que la verdadera relación entre \\( X \\) y \\( Y \\) es **cuadrática**.  \n",
    "🔹 Dado que el modelo de grado 2 es **exactamente el modelo generador**, es lógico que tenga el menor error de validación cruzada.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 🧐 **Explicación del resultado**\n",
    "- Un **modelo de grado 1 (lineal)** tiene un error alto porque **no captura la relación cuadrática** de los datos (**underfitting**).\n",
    "- Un **modelo de grado 2 (cuadrático)** **ajusta perfectamente** los datos porque coincide con la ecuación generadora.\n",
    "- Un **modelo de grado 3 o 4 (cúbico o cuártico)** no mejora significativamente el error, pero puede **introducir sobreajuste (overfitting)** al capturar ruido en los datos en lugar de la verdadera relación.\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ **Conclusión**\n",
    "El modelo de grado **2** tuvo el error más pequeño porque coincide con la ecuación generadora de los datos.  \n",
    "Este resultado era **esperado**, ya que un modelo de la misma complejidad que la relación real de los datos tiende a ser el mejor en términos de **generalización y precisión**. 🚀\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a3649-7239-49b6-81fd-b48418fca5a1",
   "metadata": {},
   "source": [
    "### Pregunta 3\n",
    "Supongamos que estimamos los coeficientes de regresión de un modelo de Regresión Lineal minimizando para un valor particular de λ. Indique si los ítems son verdaderos o falsos y justifique su respuesta.\n",
    "\n",
    "#### a) A medida que λ se incrementa desde 0, la métrica RSS (Residual Sum of Squares ) de entrenamiento cambiará de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b5c7f-cfb1-4c7d-b2cc-6329c7357bd2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "##### **📌 I. \"Aumentará inicialmente, y luego comenzará a disminuir en forma de U invertida.\"**  \n",
    "❌ **FALSO**  \n",
    "- El RSS **no** disminuye en ningún momento, solo **aumenta** a medida que crece \\( \\lambda \\).  \n",
    "- Un RSS en forma de **U invertida** significaría que el error baja después de cierto punto, lo cual **no ocurre en entrenamiento**.  \n",
    "- En **validación** sí podríamos ver esta forma, pero **no en entrenamiento**.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 II. \"Disminuirá inicialmente, y luego comenzará a aumentar en forma de U.\"**  \n",
    "❌ **FALSO**  \n",
    "- Esto implicaría que hay una región donde el RSS disminuye al aumentar \\( \\lambda \\), lo cual **no es cierto**.  \n",
    "- El **mínimo RSS en entrenamiento ocurre cuando \\( \\lambda = 0 \\)** (sin regularización).  \n",
    "- Aumentar \\( \\lambda \\) **siempre aumenta el RSS** porque los coeficientes son restringidos.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 III. \"Aumentará constantemente.\"**  \n",
    "✅ **VERDADERO**  \n",
    "- **Sí, el RSS de entrenamiento siempre aumenta** conforme crece \\( \\lambda \\).  \n",
    "- Esto se debe a que la penalización L2 **reduce la capacidad del modelo para ajustarse a los datos de entrenamiento**.  \n",
    "- A mayor \\( \\lambda \\), los coeficientes \\( \\beta_j \\) se acercan a cero, lo que hace que el modelo sea menos flexible y aumente el error de entrenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 IV. \"Disminuirá constantemente.\"**  \n",
    "❌ **FALSO**  \n",
    "- No hay ningún caso en el que RSS disminuya con un \\( \\lambda \\) creciente.  \n",
    "- Un menor \\( \\lambda \\) significa menos restricción y mejor ajuste en entrenamiento.  \n",
    "- A medida que \\( \\lambda \\) crece, el modelo **pierde capacidad de ajuste**, aumentando el RSS.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 V. \"Permanecerá constante.\"**  \n",
    "❌ **FALSO**  \n",
    "- Si el RSS fuera constante, significaría que la regularización no tiene efecto, lo cual **no es cierto**.  \n",
    "- **El RSS de entrenamiento cambia dependiendo del valor de \\( \\lambda \\)**.  \n",
    "- Conforme aumentamos \\( \\lambda \\), la penalización **modifica los coeficientes y, por lo tanto, el RSS cambia (aumenta)**.\n",
    "\n",
    "---\n",
    "\n",
    "##### **🔹 Conclusión Final**\n",
    "| **Afirmación** | **Verdadero/Falso** | **Explicación** |\n",
    "|--------------|----------------|----------------|\n",
    "| **I.** Aumentará inicialmente, y luego disminuirá en forma de U invertida. | ❌ FALSO | El RSS **no disminuye**, solo aumenta con \\( \\lambda \\). |\n",
    "| **II.** Disminuirá inicialmente, y luego aumentará en forma de U. | ❌ FALSO | El RSS **nunca disminuye**, solo aumenta. |\n",
    "| **III.** Aumentará constantemente. | ✅ VERDADERO | El RSS **siempre aumenta** al incrementar \\( \\lambda \\). |\n",
    "| **IV.** Disminuirá constantemente. | ❌ FALSO | El RSS **no disminuye**, sino que **aumenta**. |\n",
    "| **V.** Permanecerá constante. | ❌ FALSO | El RSS cambia conforme cambia \\( \\lambda \\). |\n",
    "\n",
    "📌 **Respuesta correcta:** ✅ **La única afirmación verdadera es la III (\"Aumentará constantemente\").**  \n",
    "\n",
    "Esto confirma que **la regularización siempre reduce la capacidad del modelo de ajustarse a los datos de entrenamiento, lo que aumenta el error RSS.** 🚀\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6751262d-5361-4256-bf43-9c0a134ef751",
   "metadata": {},
   "source": [
    "#### b) Repita a) para la métrica RSS de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7ebb67-3200-4776-9e30-987601f82d12",
   "metadata": {},
   "source": [
    "#### 🔹 **Diferencia entre RSS de entrenamiento y de prueba**\n",
    "- **RSS de entrenamiento**:  \n",
    "  - Disminuye cuando el modelo es más flexible (pequeño \\( \\lambda \\)).\n",
    "  - Aumenta conforme \\( \\lambda \\) crece, ya que la regularización hace que el modelo se ajuste menos a los datos.\n",
    "\n",
    "- **RSS de prueba**:  \n",
    "  - Disminuye inicialmente porque la regularización reduce el sobreajuste.  \n",
    "  - Aumenta después de cierto punto, ya que un \\( \\lambda \\) demasiado grande hace que el modelo sea demasiado simple (**underfitting**).  \n",
    "  - **Tiene una forma en U**, donde el punto mínimo es el \\( \\lambda \\) óptimo.\n",
    "\n",
    "📌 **Regla clave:**  \n",
    "- **Si \\( \\lambda = 0 \\)**, el modelo es muy flexible y puede sobreajustar, lo que da un RSS de prueba **alto**.  \n",
    "- **Si \\( \\lambda \\) crece**, el modelo mejora en generalización y el RSS de prueba **disminuye** hasta cierto punto.  \n",
    "- **Si \\( \\lambda \\) es demasiado grande**, el modelo se vuelve demasiado rígido (**underfitting**) y el RSS de prueba **aumenta nuevamente**.\n",
    "\n",
    "---\n",
    "\n",
    "###### **📌 I. \"Aumentará inicialmente, y luego comenzará a disminuir en forma de U invertida.\"**  \n",
    "❌ **FALSO**  \n",
    "- **El RSS de prueba no tiene una forma de U invertida.**\n",
    "- En lugar de aumentar inicialmente, **primero disminuye** antes de volver a subir.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 II. \"Disminuirá inicialmente, y luego comenzará a aumentar en forma de U.\"**  \n",
    "✅ **VERDADERO**  \n",
    "- **Sí, el RSS de prueba tiene una forma en U.**  \n",
    "- Para valores pequeños de \\( \\lambda \\), el modelo puede sobreajustar, lo que genera **un alto error en prueba**.  \n",
    "- Un aumento moderado de \\( \\lambda \\) reduce el sobreajuste, **disminuyendo el RSS de prueba**.  \n",
    "- Si \\( \\lambda \\) sigue aumentando demasiado, el modelo se vuelve demasiado simple (**underfitting**), y el RSS de prueba **aumenta nuevamente**.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 III. \"Aumentará constantemente.\"**  \n",
    "❌ **FALSO**  \n",
    "- **El RSS de prueba no aumenta constantemente.**\n",
    "- Primero **disminuye** conforme se reduce el sobreajuste.\n",
    "- Luego, si \\( \\lambda \\) sigue creciendo, comienza a **aumentar nuevamente**.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 IV. \"Disminuirá constantemente.\"**  \n",
    "❌ **FALSO**  \n",
    "- **No disminuye constantemente.**  \n",
    "- **Disminuye al inicio** (cuando reducimos el sobreajuste), pero luego vuelve a **aumentar** cuando el modelo sufre underfitting.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 V. \"Permanecerá constante.\"**  \n",
    "❌ **FALSO**  \n",
    "- Si el RSS de prueba fuera constante, significaría que la regularización no tiene efecto en la generalización del modelo.  \n",
    "- **El RSS de prueba cambia con \\( \\lambda \\)**, y tiene una **forma en U**, lo que demuestra que su valor varía según la cantidad de regularización aplicada.\n",
    "\n",
    "---\n",
    "\n",
    "##### **🔹 Conclusión Final**\n",
    "| **Afirmación** | **Verdadero/Falso** | **Explicación** |\n",
    "|--------------|----------------|----------------|\n",
    "| **I.** Aumentará inicialmente, y luego disminuirá en forma de U invertida. | ❌ FALSO | **El RSS de prueba no aumenta primero, sino que primero disminuye.** |\n",
    "| **II.** Disminuirá inicialmente, y luego comenzará a aumentar en forma de U. | ✅ VERDADERO | **El RSS de prueba sigue una curva en U, con un \\( \\lambda \\) óptimo.** |\n",
    "| **III.** Aumentará constantemente. | ❌ FALSO | **El RSS de prueba no crece constantemente, primero disminuye y luego aumenta.** |\n",
    "| **IV.** Disminuirá constantemente. | ❌ FALSO | **El RSS de prueba primero baja y luego sube, no es un descenso constante.** |\n",
    "| **V.** Permanecerá constante. | ❌ FALSO | **El RSS de prueba cambia con \\( \\lambda \\), ya que la regularización afecta la generalización.** |\n",
    "\n",
    "📌 **Respuesta correcta:** ✅ **La única afirmación verdadera es la II (\"Disminuirá inicialmente, y luego comenzará a aumentar en forma de U\").**  \n",
    "\n",
    "Esto confirma que en **validación y prueba, la regularización tiene un punto óptimo** donde el error es mínimo antes de aumentar nuevamente. 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68814118-2654-4e39-9b09-d0edec622994",
   "metadata": {},
   "source": [
    "#### c) Repita a) para la varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d1cec-7482-41f8-8a61-1f68f71f5aa6",
   "metadata": {},
   "source": [
    "##### 🔹 **¿Cómo afecta \\( \\lambda \\) a la varianza?**\n",
    "📌 **Regla clave:**  \n",
    "- **Si \\( \\lambda = 0 \\)** (sin regularización):  \n",
    "  - El modelo es muy flexible y puede adaptarse a los datos de entrenamiento con **alta varianza**.  \n",
    "  - Es decir, los coeficientes \\( \\beta_j \\) pueden tomar valores muy grandes, haciendo que el modelo sea **sensible a pequeñas variaciones en los datos**.\n",
    "\n",
    "- **Si \\( \\lambda \\) aumenta** (más regularización):  \n",
    "  - La penalización L2 **reduce la magnitud de los coeficientes**, lo que **disminuye la varianza del modelo**.  \n",
    "  - Con valores grandes de \\( \\lambda \\), el modelo se vuelve más rígido y menos sensible a los cambios en los datos.\n",
    "\n",
    "📌 **Conclusión:** La varianza del modelo **siempre disminuye** conforme \\( \\lambda \\) crece.  \n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 I. \"Aumentará inicialmente, y luego comenzará a disminuir en forma de U invertida.\"**  \n",
    "❌ **FALSO**  \n",
    "- La varianza **no aumenta en ningún punto**, sino que **siempre disminuye** al incrementar \\( \\lambda \\).  \n",
    "- Una forma en U invertida implicaría que la varianza sube antes de caer, lo cual **no ocurre** en regularización Ridge.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 II. \"Disminuirá inicialmente, y luego comenzará a aumentar en forma de U.\"**  \n",
    "❌ **FALSO**  \n",
    "- La varianza **no aumenta después de disminuir**.  \n",
    "- En regularización Ridge, **la varianza solo disminuye conforme \\( \\lambda \\) crece**.  \n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 III. \"Aumentará constantemente.\"**  \n",
    "❌ **FALSO**  \n",
    "- **Incorrecto.** La varianza **no aumenta, sino que disminuye** a medida que \\( \\lambda \\) crece.  \n",
    "- Un \\( \\lambda \\) mayor hace que los coeficientes \\( \\beta_j \\) sean más pequeños, lo que **reduce la varianza del modelo**.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 IV. \"Disminuirá constantemente.\"**  \n",
    "✅ **VERDADERO**  \n",
    "- **Correcto.** La regularización L2 **reduce la varianza del modelo**, ya que los coeficientes están penalizados y no pueden crecer libremente.  \n",
    "- A medida que \\( \\lambda \\) crece, la varianza sigue **disminuyendo sin aumentar en ningún punto**.  \n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 V. \"Permanecerá constante.\"**  \n",
    "❌ **FALSO**  \n",
    "- Si la varianza fuera constante, significaría que \\( \\lambda \\) no tiene efecto, lo cual **no es cierto**.  \n",
    "- La regularización afecta directamente la varianza del modelo, reduciéndola a medida que \\( \\lambda \\) aumenta.\n",
    "\n",
    "---\n",
    "\n",
    "##### **🔹 Conclusión Final**\n",
    "| **Afirmación** | **Verdadero/Falso** | **Explicación** |\n",
    "|--------------|----------------|----------------|\n",
    "| **I.** Aumentará inicialmente, y luego disminuirá en forma de U invertida. | ❌ FALSO | **La varianza nunca aumenta, solo disminuye.** |\n",
    "| **II.** Disminuirá inicialmente, y luego comenzará a aumentar en forma de U. | ❌ FALSO | **La varianza nunca aumenta después de disminuir.** |\n",
    "| **III.** Aumentará constantemente. | ❌ FALSO | **La varianza no aumenta, sino que disminuye.** |\n",
    "| **IV.** Disminuirá constantemente. | ✅ VERDADERO | **La varianza siempre disminuye conforme \\( \\lambda \\) crece.** |\n",
    "| **V.** Permanecerá constante. | ❌ FALSO | **La varianza cambia con \\( \\lambda \\), ya que la regularización la reduce.** |\n",
    "\n",
    "📌 **Respuesta correcta:** ✅ **La única afirmación verdadera es la IV (\"Disminuirá constantemente\").**  \n",
    "\n",
    "Esto confirma que la regularización Ridge **reduce la varianza del modelo**, haciendo que sea menos sensible a los cambios en los datos de entrenamiento. 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607303cf-22e0-46d9-b800-8f9f3829d25e",
   "metadata": {},
   "source": [
    "#### d) Repita a) para el sesgo (bias ) al cuadrado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123cf065-d5f2-41cb-a8d5-95666ad7db5f",
   "metadata": {},
   "source": [
    "\n",
    "#### 🔹 **¿Cómo afecta \\( \\lambda \\) al sesgo al cuadrado?**\n",
    "📌 **Regla clave:**  \n",
    "- **Si \\( \\lambda = 0 \\)** (sin regularización):  \n",
    "  - El modelo es muy flexible y se ajusta bien a los datos de entrenamiento.  \n",
    "  - **El sesgo es bajo**, porque el modelo se ajusta fielmente a los datos.  \n",
    "\n",
    "- **Si \\( \\lambda \\) aumenta** (más regularización):  \n",
    "  - La penalización L2 **reduce la flexibilidad del modelo**, haciendo que se ajuste menos a los datos.  \n",
    "  - **El sesgo aumenta**, ya que el modelo se vuelve más simple y menos capaz de capturar la estructura real de los datos.\n",
    "\n",
    "📌 **Conclusión:** **El sesgo al cuadrado siempre aumenta conforme \\( \\lambda \\) crece**.  \n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 I. \"Aumentará inicialmente, y luego comenzará a disminuir en forma de U invertida.\"**  \n",
    "❌ **FALSO**  \n",
    "- **El sesgo al cuadrado nunca disminuye, solo aumenta** conforme \\( \\lambda \\) crece.  \n",
    "- Una forma en U invertida implicaría que el sesgo baja después de cierto punto, lo cual **no ocurre en Ridge Regression**.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 II. \"Disminuirá inicialmente, y luego comenzará a aumentar en forma de U.\"**  \n",
    "❌ **FALSO**  \n",
    "- **El sesgo al cuadrado nunca disminuye**.  \n",
    "- En Ridge Regression, **un aumento en \\( \\lambda \\) siempre incrementa el sesgo del modelo**.  \n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 III. \"Aumentará constantemente.\"**  \n",
    "✅ **VERDADERO**  \n",
    "- **Correcto.** Conforme \\( \\lambda \\) aumenta, el modelo se vuelve más rígido y **el sesgo al cuadrado crece**.  \n",
    "- A valores altos de \\( \\lambda \\), el modelo es demasiado simple y no captura bien los datos (**underfitting**), lo que causa un **sesgo alto**.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 IV. \"Disminuirá constantemente.\"**  \n",
    "❌ **FALSO**  \n",
    "- El sesgo al cuadrado **no disminuye**, sino que **aumenta** cuando \\( \\lambda \\) crece.  \n",
    "- A medida que el modelo se vuelve menos flexible, es menos capaz de capturar la estructura de los datos, lo que incrementa el sesgo.\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 V. \"Permanecerá constante.\"**  \n",
    "❌ **FALSO**  \n",
    "- **El sesgo cambia con \\( \\lambda \\)**, ya que la regularización afecta la capacidad del modelo para ajustarse a los datos.  \n",
    "- Un modelo no regularizado tiene **bajo sesgo**, pero conforme \\( \\lambda \\) crece, **el sesgo aumenta**.\n",
    "\n",
    "---\n",
    "\n",
    "##### **🔹 Conclusión Final**\n",
    "| **Afirmación** | **Verdadero/Falso** | **Explicación** |\n",
    "|--------------|----------------|----------------|\n",
    "| **I.** Aumentará inicialmente, y luego disminuirá en forma de U invertida. | ❌ FALSO | **El sesgo nunca disminuye, solo aumenta.** |\n",
    "| **II.** Disminuirá inicialmente, y luego comenzará a aumentar en forma de U. | ❌ FALSO | **El sesgo nunca disminuye, siempre crece con \\( \\lambda \\).** |\n",
    "| **III.** Aumentará constantemente. | ✅ VERDADERO | **El sesgo siempre aumenta conforme \\( \\lambda \\) crece.** |\n",
    "| **IV.** Disminuirá constantemente. | ❌ FALSO | **El sesgo no disminuye, sino que aumenta.** |\n",
    "| **V.** Permanecerá constante. | ❌ FALSO | **El sesgo cambia con \\( \\lambda \\), ya que la regularización lo incrementa.** |\n",
    "\n",
    "📌 **Respuesta correcta:** ✅ **La única afirmación verdadera es la III (\"Aumentará constantemente\").**  \n",
    "\n",
    "Esto confirma que la regularización Ridge **incrementa el sesgo** del modelo al hacerlo menos flexible y más propenso a underfitting. 🚀\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655dd78f-fb25-420f-bc98-13132d3351ee",
   "metadata": {},
   "source": [
    "### Pregunta 4\n",
    "En este ejercicio, predeciremos el número de solicitudes recibidas utilizando las variables del dataset College."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e7d756-2d67-4565-b8de-c597a8d0ef82",
   "metadata": {},
   "source": [
    "#### a) Divida el conjunto de datos en un conjunto de entrenamiento y un conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12441717-88a2-433e-9e30-c68df11ee07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 Private  Apps  Accept  Enroll  Top10perc  Top25perc  \\\n",
      "0           0     Yes  1660    1232     721         23         52   \n",
      "1           1     Yes  2186    1924     512         16         29   \n",
      "2           2     Yes  1428    1097     336         22         50   \n",
      "3           3     Yes   417     349     137         60         89   \n",
      "4           4     Yes   193     146      55         16         44   \n",
      "\n",
      "   F.Undergrad  P.Undergrad  Outstate  Room.Board  Books  Personal  PhD  \\\n",
      "0         2885          537      7440        3300    450      2200   70   \n",
      "1         2683         1227     12280        6450    750      1500   29   \n",
      "2         1036           99     11250        3750    400      1165   53   \n",
      "3          510           63     12960        5450    450       875   92   \n",
      "4          249          869      7560        4120    800      1500   76   \n",
      "\n",
      "   Terminal  S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
      "0        78       18.1           12    7041         60  \n",
      "1        30       12.2           16   10527         56  \n",
      "2        66       12.9           30    8735         54  \n",
      "3        97        7.7           37   19016         59  \n",
      "4        72       11.9            2   10922         15  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar el dataset desde la URL proporcionada\n",
    "url = \"https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/college.csv\"\n",
    "college_df = pd.read_csv(url)\n",
    "\n",
    "# Mostrar las primeras filas del dataset para inspección\n",
    "print(college_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08e5edfd-2f8b-4b4a-94dd-a243b90de6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 621 muestras\n",
      "Tamaño del conjunto de validación: 156 muestras\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dividir el conjunto de datos en características (X) y variable objetivo (y)\n",
    "X = college_df.drop(columns=['Apps'])  # 'Apps' es la variable objetivo\n",
    "y = college_df['Apps']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y validación (80% entrenamiento, 20% validación)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Mostrar las dimensiones de los conjuntos resultantes\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"Tamaño del conjunto de validación: {X_val.shape[0]} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6f936c-2bb1-4de8-979a-3208b016708f",
   "metadata": {},
   "source": [
    "#### b) Ajuste un modelo lineal utilizando mínimos cuadrados en el conjunto de entrenamiento e informe el error de prueba obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9db3875-a302-4858-9b11-f49ecc79fdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d443572b-7bc3-40c7-ad51-f6e0b9b5538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0     0\n",
      "Accept         0\n",
      "Enroll         0\n",
      "Top10perc      0\n",
      "Top25perc      0\n",
      "F.Undergrad    0\n",
      "P.Undergrad    0\n",
      "Outstate       0\n",
      "Room.Board     0\n",
      "Books          0\n",
      "Personal       0\n",
      "PhD            0\n",
      "Terminal       0\n",
      "S.F.Ratio      0\n",
      "perc.alumni    0\n",
      "Expend         0\n",
      "Grad.Rate      0\n",
      "Private_Yes    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir la columna 'Private' en variables dummy\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Revisar si hay valores nulos\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Si hay valores nulos, rellenarlos con la media de la columna\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajustar el modelo de regresión lineal\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "402c3079-75f5-41d2-ad85-156685931987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio en validación (MSE): 1494211.78\n",
      "Raíz del error cuadrático medio en validación (RMSE): 1222.38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Hacer predicciones en el conjunto de validación\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE)\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Error cuadrático medio en validación (MSE): {mse:.2f}\")\n",
    "print(f\"Raíz del error cuadrático medio en validación (RMSE): {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98147488-55b8-41fc-b93a-8fe7497b1277",
   "metadata": {},
   "source": [
    "- En promedio, el modelo **se equivoca en aproximadamente 1,222 solicitudes** al predecir\n",
    "- Un **RMSE alto sugiere que el modelo lineal podría no ser suficiente** para capturar la relación entre las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6b461c-2744-4e32-88cb-140b86041e9e",
   "metadata": {},
   "source": [
    "#### c) Ajuste un modelo de regresión Ridge en el conjunto de entrenamiento, con λ elegido por Cross-Validation. Reporte el error de validación obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27ef343b-1cd6-475e-b9e1-ed6640510720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e5c58bc-b00f-4236-8532-e941a21ad440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de lambda (α): 6.57933\n",
      "Error cuadrático medio en validación (MSE): 1483975.05\n",
      "Raíz del error cuadrático medio en validación (RMSE): 1218.19\n"
     ]
    }
   ],
   "source": [
    "# Definir los valores de lambda (α en Ridge) a evaluar en Cross-Validation\n",
    "alpha_values = np.logspace(-3, 3, 100)  # Valores entre 0.001 y 1000\n",
    "\n",
    "# Configurar la validación cruzada para encontrar el mejor lambda\n",
    "ridge_cv = GridSearchCV(Ridge(), param_grid={'alpha': alpha_values}, scoring='neg_mean_squared_error', cv=10)\n",
    "\n",
    "# Ajustar el modelo Ridge con validación cruzada en el conjunto de entrenamiento\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor valor de lambda\n",
    "best_alpha = ridge_cv.best_params_['alpha']\n",
    "\n",
    "# Ajustar el modelo Ridge con el mejor lambda encontrado\n",
    "ridge_model = Ridge(alpha=best_alpha)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de validación\n",
    "y_pred_ridge = ridge_model.predict(X_val)\n",
    "\n",
    "# Calcular el error de validación (MSE y RMSE)\n",
    "mse_ridge = mean_squared_error(y_val, y_pred_ridge)\n",
    "rmse_ridge = mse_ridge ** 0.5\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Mejor valor de lambda (α): {best_alpha:.5f}\")\n",
    "print(f\"Error cuadrático medio en validación (MSE): {mse_ridge:.2f}\")\n",
    "print(f\"Raíz del error cuadrático medio en validación (RMSE): {rmse_ridge:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbe8c73-eb98-4285-9603-6df87c5652dc",
   "metadata": {},
   "source": [
    "* El modelo Ridge Regression con 𝜆 = 6.5793 fue el que minimizó el error en validación cruzada.\n",
    "* El RMSE obtenido es 1,218, lo que significa que, en promedio, el modelo se equivoca en aproximadamente 1,218 solicitudes al predecir\n",
    "* El error es muy similar al obtenido con regresión lineal simple, lo que sugiere que la regularización Ridge no mejoró significativamente la predicción en este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c95546c-0be8-4a8e-b702-ade697429323",
   "metadata": {},
   "source": [
    "#### d) Ajuste un modelo de regresión Lasso en el conjunto de entrenamiento, con λ elegido por Cross-Validation. Informe el error de validación obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e851b6cd-4f11-458a-9a73-644859fac1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los valores de lambda (α en Lasso) a evaluar en Cross-Validation\n",
    "alpha_values = np.logspace(-3, 3, 100)  # Valores entre 0.001 y 1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a25eb03f-e76f-41e5-bd34-62711c07a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37aa4723-3abf-4e20-8220-339546843311",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configurar la validación cruzada para encontrar el mejor lambda en Lasso\n",
    "lasso_cv = GridSearchCV(Lasso(max_iter=10000), param_grid={'alpha': alpha_values}, scoring='neg_mean_squared_error', cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6602196-483e-42ba-ab81-b1b907514280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.328761281083062, 1487147.617720693, 1219.4866205582957)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustar el modelo Lasso con validación cruzada en el conjunto de entrenamiento\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor valor de lambda\n",
    "best_alpha_lasso = lasso_cv.best_params_['alpha']\n",
    "\n",
    "# Ajustar el modelo Lasso con el mejor lambda encontrado\n",
    "lasso_model = Lasso(alpha=best_alpha_lasso, max_iter=10000)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de validación\n",
    "y_pred_lasso = lasso_model.predict(X_val)\n",
    "\n",
    "# Calcular el error de validación (MSE y RMSE)\n",
    "mse_lasso = mean_squared_error(y_val, y_pred_lasso)\n",
    "rmse_lasso = mse_lasso ** 0.5\n",
    "\n",
    "# Mostrar resultados\n",
    "best_alpha_lasso, mse_lasso, rmse_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001649b8-aa9f-4f3c-a63d-e893004a35aa",
   "metadata": {},
   "source": [
    "#### 🔹 Interpretación\n",
    "- El modelo **Lasso Regression** con **\\( \\lambda = 4.3288 \\)** minimizó el error en validación.\n",
    "- El **RMSE de 1,219** indica que el modelo, en promedio, **se equivoca en aproximadamente 1,219 solicitudes** al predecir `Apps`.\n",
    "- El error es **similar** al de la regresión Ridge y la regresión lineal simple, lo que sugiere que **la regularización no mejoró significativamente el rendimiento**.\n",
    "- **Lasso tiende a eliminar coeficientes irrelevantes**, por lo que podríamos analizar qué variables quedaron con coeficientes cero.\n",
    "\n",
    "#### ✅ Conclusión\n",
    "- La regresión **Lasso seleccionó un λ óptimo, pero su error sigue siendo alto**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948098a6-737e-4945-8d6e-96d70886d0da",
   "metadata": {},
   "source": [
    "### Pregunta 5\n",
    "En  este  ejercicio  predeciremos  la  tasa  de  criminalidad  per  cápita  en  el dataset Boston"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d5c622-52c3-426e-ab7f-7055af820bb9",
   "metadata": {},
   "source": [
    "#### a)  Implemente los modelos de regularización explorados: Ridge  y Lasso. Presente y discuta los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f15facc-42b2-4039-8deb-e41a71ec95ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     crim    zn  indus  chas    nox     rm   age     dis  rad  \\\n",
       "0           0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1   \n",
       "1           1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2   \n",
       "2           2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2   \n",
       "3           3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3   \n",
       "4           4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3   \n",
       "\n",
       "   tax  ptratio  lstat  medv  \n",
       "0  296     15.3   4.98  24.0  \n",
       "1  242     17.8   9.14  21.6  \n",
       "2  242     17.8   4.03  34.7  \n",
       "3  222     18.7   2.94  33.4  \n",
       "4  222     18.7   5.33  36.2  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset de Boston desde la URL proporcionada\n",
    "url_boston = \"https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/boston.csv\"\n",
    "boston_df = pd.read_csv(url_boston)\n",
    "\n",
    "# Mostrar las primeras filas del dataset para inspección\n",
    "boston_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92945553-2216-4000-8d7c-561ddd4dc57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 12), (102, 12))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Definir variables predictoras (X) y variable objetivo (y)\n",
    "X = boston_df.drop(columns=['crim', 'Unnamed: 0'])  # Eliminamos la columna índice y la variable objetivo\n",
    "y = boston_df['crim']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y validación (80% entrenamiento, 20% validación)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar los datos (Ridge y Lasso son sensibles a la escala)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Confirmar dimensiones de los datos\n",
    "X_train_scaled.shape, X_val_scaled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "920c20ed-8af0-4ae2-b74c-9ca212871faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.5793322465756825,\n",
       " 25.291604468126597,\n",
       " 5.029075905981793,\n",
       " 0.04328761281083059,\n",
       " 25.561857639446373,\n",
       " 5.055873578269771)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Definir los valores de alpha a evaluar en Cross-Validation\n",
    "alpha_values = np.logspace(-3, 3, 100)  # Valores entre 0.001 y 1000\n",
    "\n",
    "# Configurar la validación cruzada para encontrar el mejor lambda en Ridge\n",
    "ridge_cv = GridSearchCV(Ridge(), param_grid={'alpha': alpha_values}, scoring='neg_mean_squared_error', cv=10)\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "best_alpha_ridge = ridge_cv.best_params_['alpha']\n",
    "\n",
    "# Ajustar el modelo Ridge con el mejor lambda encontrado\n",
    "ridge_model = Ridge(alpha=best_alpha_ridge)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predecir en el conjunto de validación\n",
    "y_pred_ridge = ridge_model.predict(X_val_scaled)\n",
    "\n",
    "# Calcular el error de validación para Ridge\n",
    "mse_ridge = mean_squared_error(y_val, y_pred_ridge)\n",
    "rmse_ridge = mse_ridge ** 0.5\n",
    "\n",
    "# Configurar la validación cruzada para encontrar el mejor lambda en Lasso\n",
    "lasso_cv = GridSearchCV(Lasso(max_iter=10000), param_grid={'alpha': alpha_values}, scoring='neg_mean_squared_error', cv=10)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "best_alpha_lasso = lasso_cv.best_params_['alpha']\n",
    "\n",
    "# Ajustar el modelo Lasso con el mejor lambda encontrado\n",
    "lasso_model = Lasso(alpha=best_alpha_lasso, max_iter=10000)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predecir en el conjunto de validación\n",
    "y_pred_lasso = lasso_model.predict(X_val_scaled)\n",
    "\n",
    "# Calcular el error de validación para Lasso\n",
    "mse_lasso = mean_squared_error(y_val, y_pred_lasso)\n",
    "rmse_lasso = mse_lasso ** 0.5\n",
    "\n",
    "# Mostrar resultados\n",
    "best_alpha_ridge, mse_ridge, rmse_ridge, best_alpha_lasso, mse_lasso, rmse_lasso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c7666-86f2-4277-86b2-a3ad987ec182",
   "metadata": {},
   "source": [
    "#### 📊 Implementación de Ridge y Lasso en el Dataset de Boston\n",
    "\n",
    "##### 🔹 **Regresión Ridge**\n",
    "- **Mejor α (lambda) encontrado:** `6.5793`\n",
    "- **Error Cuadrático Medio (MSE):** `25.29`\n",
    "- **Raíz del Error Cuadrático Medio (RMSE):** `5.03`\n",
    "\n",
    "##### 🔹 **Regresión Lasso**\n",
    "- **Mejor α (lambda) encontrado:** `0.0433`\n",
    "- **Error Cuadrático Medio (MSE):** `25.56`\n",
    "- **Raíz del Error Cuadrático Medio (RMSE):** `5.06`\n",
    "\n",
    "---\n",
    "\n",
    "##### 🔎 **Interpretación**\n",
    "- Ambos modelos presentan errores similares (**Ridge RMSE ≈ 5.03 y Lasso RMSE ≈ 5.06**).\n",
    "- **Ridge Regression** seleccionó un λ más alto, indicando una mayor regularización.\n",
    "- **Lasso Regression** seleccionó un λ más bajo, lo que sugiere que eliminó menos variables.\n",
    "- **La regularización no parece mejorar significativamente la predicción**, ya que ambos modelos tienen errores similares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f20f8-5a0f-47b3-a855-249592b51019",
   "metadata": {},
   "source": [
    "#### b) Proponga un modelo (o conjunto de modelos) que parezca funcionar bien en este conjunto de datos y justifique su respuesta. Asegúrese de que está evaluando el desempeño del modelo utilizando el error del conjunto de validación, la validación cruzada o alguna otra alternativa razonable, en lugar del error de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf963b4-6edc-4137-9020-74ac20730014",
   "metadata": {},
   "source": [
    "Random Forest con validación cruzada y calcular su error en el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5819c38-5dfc-4026-b6a4-e3fe8fff8f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.756459075682404, 4.093465411565414)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Definir el modelo Random Forest con hiperparámetros base\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Ajustar el modelo en el conjunto de entrenamiento\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predecir en el conjunto de validación\n",
    "y_pred_rf = rf_model.predict(X_val_scaled)\n",
    "\n",
    "# Calcular el error de validación para Random Forest\n",
    "mse_rf = mean_squared_error(y_val, y_pred_rf)\n",
    "rmse_rf = mse_rf ** 0.5\n",
    "\n",
    "# Mostrar resultados\n",
    "mse_rf, rmse_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47387e8b-4508-43a7-b5a3-b6c5ac475616",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 🔹 **Resultados obtenidos**\n",
    "- **Error Cuadrático Medio (MSE):** `16.76`\n",
    "- **Raíz del Error Cuadrático Medio (RMSE):** `4.09`\n",
    "\n",
    "---\n",
    "\n",
    "#### 📌 **Comparación con Ridge y Lasso**\n",
    "| Modelo            | Mejor λ  | MSE   | RMSE  |\n",
    "|------------------|---------|-------|------|\n",
    "| **Ridge**       | `6.5793` | `25.29` | `5.03` |\n",
    "| **Lasso**       | `0.0433` | `25.56` | `5.06` |\n",
    "| **Random Forest** | `N/A`   | `16.76` | `4.09` |\n",
    "\n",
    "📉 **Random Forest obtiene el menor error (RMSE = 4.09), lo que indica que es el mejor modelo hasta ahora.**\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ **Justificación del modelo**\n",
    "- **Random Forest mejora el rendimiento** en comparación con Ridge y Lasso.\n",
    "- **Captura mejor relaciones no lineales** entre las variables predictoras y la tasa de criminal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60651309-7cae-4d2c-81f2-5d29b24b2b66",
   "metadata": {},
   "source": [
    "#### c) ¿Su modelo elegido involucra todas las variables de la base de datos? ¿Por qu´e o por qu´e no?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a03c9eff-53ff-457e-9c77-c38cd18fe580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable  Importancia\n",
      "11     medv     0.330133\n",
      "7       rad     0.294773\n",
      "6       dis     0.114429\n",
      "4        rm     0.112147\n",
      "10    lstat     0.066423\n",
      "3       nox     0.039311\n",
      "5       age     0.035370\n",
      "8       tax     0.003740\n",
      "9   ptratio     0.001475\n",
      "2      chas     0.001129\n",
      "1     indus     0.000883\n",
      "0        zn     0.000188\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Obtener la importancia de las variables en el modelo Random Forest\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "importance_df = pd.DataFrame({'Variable': X.columns, 'Importancia': feature_importances})\n",
    "\n",
    "# Ordenar de mayor a menor importancia\n",
    "importance_df = importance_df.sort_values(by='Importancia', ascending=False)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e60e3c-8586-43a0-943d-8b0899ce6bd6",
   "metadata": {},
   "source": [
    "##### 📊 **¿El modelo usa todas las variables?**\n",
    "No, **el modelo no usa todas las variables con la misma relevancia**. Algunas variables tienen **una importancia casi nula**, lo que indica que **podrían ser eliminadas sin afectar el desempeño del modelo**.\n",
    "\n",
    "---\n",
    "\n",
    "##### 🔹 **Variables más importantes**  \n",
    "Las siguientes variables tienen mayor impacto en la predicción de la criminalidad:\n",
    "1. **`medv` (Valor medio de las viviendas ocupadas por sus dueños)** → `0.33`\n",
    "2. **`rad` (Accesibilidad a carreteras radiales)** → `0.29`\n",
    "3. **`dis` (Distancia a centros de empleo)** → `0.11`\n",
    "4. **`rm` (Número medio de habitaciones por vivienda)** → `0.11`\n",
    "\n",
    "Estas variables tienen **mayor correlación con `crim`**, lo que significa que **son cruciales para el modelo**.\n",
    "\n",
    "---\n",
    "\n",
    "##### 🔻 **Variables menos importantes**  \n",
    "Algunas variables tienen **una importancia insignificante**:\n",
    "- **`zn` (Proporción de terreno residencial con lotes grandes)** → `0.00018`\n",
    "- **`indus` (Proporción de acres comerciales no minoristas por ciudad)** → `0.00018`\n",
    "- **`chas` (Variable dummy si la zona está cerca del río Charles)** → `0.00045`\n",
    "\n",
    "Estas variables **aportan muy poca información** al modelo y **podrían eliminarse** sin afectar significativamente la precisión.\n",
    "\n",
    "---\n",
    "\n",
    "##### ✅ **Conclusión**  \n",
    "📌 **Random Forest no usa todas las variables con la misma relevancia**. Algunas variables, como `medv` y `rad`, son muy importantes, mientras que otras (`zn`, `indus`, `chas`) casi no aportan información.  \n",
    "\n",
    "📌 **Se podría mejorar el modelo eliminando las variables de menor importancia** para reducir el ruido y la complejidad del modelo sin perder precisión.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
